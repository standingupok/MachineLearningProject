{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0af028f8-942e-4f55-b3d9-3a13e17e0804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 0.6931\n",
      "Iteration 100: Loss = 0.3194\n",
      "Iteration 200: Loss = 0.2300\n",
      "Iteration 300: Loss = 0.1747\n",
      "Iteration 400: Loss = 0.1388\n",
      "Iteration 500: Loss = 0.1141\n",
      "Iteration 600: Loss = 0.0963\n",
      "Iteration 700: Loss = 0.0830\n",
      "Iteration 800: Loss = 0.0728\n",
      "Iteration 900: Loss = 0.0647\n",
      "Trọng số tối ưu (theta):\n",
      "[[-5.56716794]\n",
      " [ 0.56612821]\n",
      " [ 0.81141435]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Dữ liệu mẫu (mẫu nhỏ để minh họa)\n",
    "X = np.array([[1, 2, 3],  # Ma trận đặc trưng (m x n)\n",
    "              [1, 4, 9],\n",
    "              [1, 6, 7]])  # Mỗi hàng là một mẫu (3 mẫu, 3 đặc trưng)\n",
    "Y = np.array([[0],         # Vector nhãn (m x 1)\n",
    "              [1],\n",
    "              [1]])\n",
    "\n",
    "# 2. Hàm sigmoid\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# 3. Hàm tính mất mát (log loss)\n",
    "def compute_loss(h, y):\n",
    "    m = y.shape[0]\n",
    "    return -1 / m * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "\n",
    "# 4. Cài đặt Gradient Descent\n",
    "def gradient_descent(X, Y, theta, learning_rate, iterations):\n",
    "    m = X.shape[0]  # Số mẫu\n",
    "    for i in range(iterations):\n",
    "        # Dự đoán với hàm sigmoid\n",
    "        z = np.dot(X, theta)          # z = X * theta\n",
    "        h = sigmoid(z)                # h = sigmoid(z)\n",
    "        # err = h - Y\n",
    "        # print(z)\n",
    "        # print(h)\n",
    "        # print(err)\n",
    "\n",
    "        # Tính gradient: grad = (1/m) * X.T * (h - Y)\n",
    "        grad = (1 / m) * np.dot(X.T, (h - Y))\n",
    "\n",
    "        # Cập nhật theta: theta = theta - alpha * grad\n",
    "        theta -= learning_rate * grad\n",
    "\n",
    "        # Tùy chọn: In loss mỗi 100 vòng\n",
    "        if i % 100 == 0:\n",
    "            loss = compute_loss(h, Y)\n",
    "            print(f\"Iteration {i}: Loss = {loss:.4f}\")\n",
    "    return theta\n",
    "\n",
    "# 5. Khởi tạo tham số\n",
    "theta = np.zeros((X.shape[1], 1))  # Vector trọng số (n x 1), ban đầu là 0\n",
    "learning_rate = 0.1\n",
    "iterations = 1000\n",
    "\n",
    "# 6. Chạy thuật toán\n",
    "theta_final = gradient_descent(X, Y, theta, learning_rate, iterations)\n",
    "\n",
    "# 7. In kết quả\n",
    "print(\"Trọng số tối ưu (theta):\")\n",
    "print(theta_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d21180b-55cc-47bb-91ac-0d83b097ab4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
